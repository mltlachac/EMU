{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import random\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import xgboost as xgb\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from statistics import mean \n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modality = 'audio_open'\n",
    "feature_selection = 'chi2' #pca, chi2, etc\n",
    "cross_validation = \"loo\"\n",
    "sampling = \"regular_oversampling\"\n",
    "target_type = \"q9\" #phq, gad, q9\n",
    "split = 1\n",
    "target_to_classes = True\n",
    "\n",
    "# Random Undersample uses imblearn library by randomly sampling data from the majority set \n",
    "def random_undersample(train_data):\n",
    "    rus = RandomUnderSampler()\n",
    "    featureSubset, featureSubset_labels = rus.fit_sample(\n",
    "        train_data.drop('target', axis=1), \n",
    "        train_data['target'])\n",
    "    return featureSubset, featureSubset_labels\n",
    "# Random Upsample uses imblearn library by randomly sampling data from the minority set \n",
    "def random_upsample(train_data):\n",
    "    ros = RandomOverSampler()\n",
    "    featureSubset, featureSubset_labels = ros.fit_sample(\n",
    "        train_data.drop('target', axis=1), \n",
    "        train_data['target'])\n",
    "    return featureSubset, featureSubset_labels\n",
    "# SMOTE Upsample uses SMOTE library by generating new data after analyzing the minority set\n",
    "def SMOTE_upsample(train_data):\n",
    "    oversample = SMOTE()\n",
    "    featureSubset, featureSubset_labels = oversample.fit_sample(\n",
    "        train_data.iloc[:,:-1], \n",
    "        train_data.iloc[:,-1])\n",
    "    return featureSubset, featureSubset_labels\n",
    "# Scale features & then run feature selection on train set and extract those features from test set\n",
    "def scale_feature_select(train_data, train_label, test_data, test_label, num_f, cnames, fnames, random_state):\n",
    "    min_max_scaler = preprocessing.MinMaxScaler().fit(train_data)\n",
    "    train_data = min_max_scaler.transform(train_data)\n",
    "    test_data = min_max_scaler.transform(test_data)\n",
    "    if feature_selection == 'pca':\n",
    "        # pca_columns = []\n",
    "        # for num_f in nFeatureList:\n",
    "        pca = PCA(n_components=num_f, random_state=random_state)\n",
    "        pca = pca.fit(train_data)\n",
    "\n",
    "        pca_weights = pd.DataFrame(pca.components_, columns=fnames).transpose()\n",
    "        #pca_weights.to_csv('resultsAudioTranscript/pca_weights_' + args.modality + '.csv')\n",
    "\n",
    "        train_data = pca.transform(train_data)\n",
    "        train_data = pd.DataFrame(train_data).assign(target = train_label)\n",
    "        test_data = pca.transform(test_data)\n",
    "        test_data = pd.DataFrame(test_data).assign(target = test_label)\n",
    "        # var = pca.explained_variance_ratio_\n",
    "        # if args.run_pca_visualizations == True:\n",
    "        #     run_pca_visualizations(pca, var, featureDF, pca_columns)\n",
    "    elif feature_selection == 'chi2':\n",
    "        chi = SelectKBest(chi2, k=num_f)\n",
    "        chi = chi.fit(train_data, train_label)\n",
    "\n",
    "        feature_idx = chi.get_support()\n",
    "        feature_name = cnames[1:-3][feature_idx].tolist()\n",
    "        features_list.append(feature_name)\n",
    "\n",
    "        # booleans of columns list\n",
    "        # mask = selector.get_support()\n",
    "        train_data = chi.transform(train_data)\n",
    "        train_data = pd.DataFrame(train_data).assign(target = train_label)\n",
    "        # indices of chi2 columns\n",
    "        # f_cols = train_data.columns[mask]\n",
    "        test_data = chi.transform(test_data)\n",
    "        test_data = pd.DataFrame(test_data).assign(target = test_label)\n",
    "    elif feature_selection == 'etc':\n",
    "        # feature_clf = ExtraTreesClassifier(n_estimators=50)\n",
    "        extra_tree_forest = ExtraTreesClassifier(random_state=random_state)\n",
    "        extra_tree_forest = extra_tree_forest.fit(train_data, train_label)\n",
    "        f_selected = SelectFromModel(extra_tree_forest, prefit=True, max_features=num_f)\n",
    "\n",
    "        feature_idx = f_selected.get_support()\n",
    "        feature_name = cnames[1:-3][feature_idx].tolist()\n",
    "        features_list.append(feature_name)\n",
    "\n",
    "        train_data = f_selected.transform(train_data)\n",
    "        train_data = pd.DataFrame(train_data).assign(target = train_label) \n",
    "        test_data = f_selected.transform(test_data)\n",
    "        test_data = pd.DataFrame(test_data).assign(target = test_label) \n",
    "    return train_data, test_data\n",
    "# finish preparing data and run through models\n",
    "def run_models(train_data, train_label, test_data, test_label, train_index, test_index, num_f, cnames, fnames, random_state, temp_num=0):\n",
    "    # run feature selection\n",
    "    train_data, test_data = scale_feature_select(train_data, train_label, test_data, test_label, num_f, cnames, fnames, random_state)\n",
    "    # run SMOTE oversampling\n",
    "    if sampling == \"smote\":\n",
    "        featureSubset, featureSubset_labels = SMOTE_upsample(train_data)\n",
    "    # run regular oversampling\n",
    "    elif sampling == \"regular_oversampling\": \n",
    "        featureSubset, featureSubset_labels = random_upsample(train_data)\n",
    "    # run regular undersampling\n",
    "    elif sampling == 'regular_undersampling':\n",
    "        featureSubset, featureSubset_labels = random_undersample(train_data)\n",
    "    for modelType in modelTypelist:\n",
    "        #select model\n",
    "        if modelType == \"SVC1\":\n",
    "            clf = svm.SVC(kernel='rbf', random_state=random_state)\n",
    "        elif modelType == \"SVC2\":\n",
    "            clf = svm.SVC(kernel='linear', random_state=random_state)\n",
    "        elif modelType == \"RF\":\n",
    "            #clf = RandomForestClassifier(criterion=\"gini\", max_depth=3, random_state=r)\n",
    "            clf = RandomForestClassifier(random_state=random_state)\n",
    "        elif modelType == \"kNN3\":\n",
    "            clf = KNeighborsClassifier(n_neighbors=3)\n",
    "        elif modelType == \"XG\":\n",
    "            clf = xgb.XGBClassifier(random_state=random_state)\n",
    "        elif modelType == \"LR\":\n",
    "            clf = LogisticRegression(max_iter=300, random_state=random_state)\n",
    "        elif modelType == \"NB\":\n",
    "            clf = GaussianNB()\n",
    "\n",
    "        # convert balanced feature training set into dataframe\n",
    "        train_dataFb = pd.DataFrame(featureSubset)\n",
    "        # convert corresponding training labels into dataframe\n",
    "        train_targetb = pd.DataFrame(featureSubset_labels)\n",
    "        # remove label from test set\n",
    "        test_dataF = test_data.iloc[:,:-1] #remove target \n",
    "        # convert test set to dataframe\n",
    "        test_dataF_df = pd.DataFrame(test_dataF)\n",
    "\n",
    "        #fit model and make predictions\n",
    "        model = clf.fit(train_dataFb.to_numpy(), train_targetb.to_numpy()) #balanced training data\n",
    "        result = model.predict(test_dataF_df.to_numpy()) #make predictions from testing data \n",
    "\n",
    "        #add to lists for df\n",
    "        mlist.append(modelType)\n",
    "        flist.append(num_f)\n",
    "        pqtrain.append(train_index)\n",
    "        pqtest.append(test_index)\n",
    "        predictions.append(result.tolist())\n",
    "        realvalues.append(test_label[0].to_list())\n",
    "        \n",
    "        #prepare evaluation results data\n",
    "        if cross_validation == 'tts':\n",
    "            if (modelType, num_f) not in results:\n",
    "                results[(modelType, num_f)] = {\"prediction\": [], \"true\": [], \"auc\":[], \"f1\":[], \"acc\":[]}             \n",
    "            else:\n",
    "                results[(modelType, num_f)][\"prediction\"].append(result)\n",
    "                results[(modelType, num_f)][\"true\"].append(test_label)\n",
    "\n",
    "                results[(modelType, num_f)][\"auc\"].append(roc_auc_score(test_label, result))\n",
    "                results[(modelType, num_f)][\"f1\"].append(f1_score(test_label, result))\n",
    "                results[(modelType, num_f)][\"acc\"].append(accuracy_score(test_label, result))\n",
    "\n",
    "        if cross_validation == 'loo':\n",
    "            if (modelType, num_f) not in results:\n",
    "                results[(modelType, num_f)] = {\"prediction\": [], \"true\": []}             \n",
    "            \n",
    "            results[(modelType, num_f)][\"prediction\"].append(result)\n",
    "            results[(modelType, num_f)][\"true\"].append(test_data.target[0])\n",
    "# calculate metrics based on true values and results\n",
    "def calculate_metrics(true_values, prediction_values):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    for i in range(len(prediction_values)): \n",
    "        if true_values[i]==prediction_values[i]==1:\n",
    "           TP += 1\n",
    "        if prediction_values[i]==1 and true_values[i]!=prediction_values[i]:\n",
    "           FP += 1\n",
    "        if true_values[i]==prediction_values[i]==0:\n",
    "           TN += 1\n",
    "        if prediction_values[i]==0 and true_values[i]!=prediction_values[i]:\n",
    "           FN += 1\n",
    "    return(TP, FP, TN, FN)\n",
    "# import data and run program based on parameters\n",
    "def main():\n",
    "    randoms = [481998864, 689799321, 796360373, 325345551, 781053364, 425410490, 448592531, 477651899, 256556897, 950476446, 439161956, 617662138, 919221369, 372092462, 978558065, 915406186, 914758288, 270769509, 348581119, 620469471, 968622238, 493269528, 923889165, 187902000, 768516562, 656996274, 204570914, 478659400, 591118631, 455578751, 523453979, 904238395, 870935338, 65160836, 469733522, 301035177, 843432976, 931667506, 283989232, 77803117, 371210776, 231366353, 454473430, 335714437, 233937007, 131940380, 267081710, 208764677, 225578708, 684893704, 93911936, 333598779, 253843993, 390054067, 432395108, 730697387, 988951427, 963369310, 983748712, 206214635, 607442488, 783641874, 444298574, 799459448, 736269849, 222259535, 501043573, 914806112, 780691269, 993143254, 900823730, 946288505, 776711331, 393086523, 366784871, 181714875, 239540123, 101370413, 417433780, 288079126, 205915691, 73435964, 248074219, 582671864, 635043553, 338657949, 330517223, 804096498, 667716642, 995598949, 504427080, 778739823, 245211208, 96486247, 541502147, 5680657, 590309190, 5062322, 921199528, 188694207]\n",
    "    random.seed(randoms[0])\n",
    "    np.random.seed(randoms[0])\n",
    "    # pd.random.seed(randoms[0])\n",
    "    random_state = randoms[0]\n",
    "\n",
    "    # \"./open_smile_features_closed_with_phq_gad.csv\"\n",
    "    # \"feature_extraction_audio/openSMILE/open_smile_features_closed_with_phq_gad.csv\"\n",
    "\n",
    "    #for both types of features\n",
    "    transcript = pd.read_csv(\"textfeatures2021.csv\")\n",
    "    audio = pd.read_csv(\"open_smile_features_open_uncleaned_gender_phq_gad.csv\")\n",
    "    print(audio.shape)\n",
    "    print(transcript.shape)\n",
    "    data = transcript.merge(audio, on = \"ID\", how = \"inner\")\n",
    "    print(data.shape)\n",
    "    print(data.columns)\n",
    "    \n",
    "    #for audio features with transcript subset\n",
    "    #transcript = pd.read_csv(\"textfeatures2021.csv\")\n",
    "    #audio = pd.read_csv(\"open_smile_features_open_uncleaned_gender_phq_gad.csv\")\n",
    "    #transcript = transcript[transcript.columns[0:1]]\n",
    "    #print(audio.shape)\n",
    "    #print(transcript.shape)\n",
    "    #data = transcript.merge(audio, on = \"ID\", how = \"inner\")\n",
    "    #print(data.shape)\n",
    "    #print(data.columns)\n",
    "    \n",
    "    #for transcript features with audio labels\n",
    "    #transcript = pd.read_csv(\"textfeatures2021.csv\")\n",
    "    #audio = pd.read_csv(\"open_smile_features_open_uncleaned_gender_phq_gad.csv\")\n",
    "    #audio = audio.iloc[:, [0,-3,-2,-1]]\n",
    "    #print(audio.shape)\n",
    "    #print(transcript.shape)\n",
    "    #data = transcript.merge(audio, on = \"ID\", how = \"inner\")\n",
    "    #print(data.shape)\n",
    "    #print(data.columns)\n",
    "    \n",
    "    df = data\n",
    "    cnames = df.columns\n",
    "    fnames = cnames[1:-3]\n",
    "\n",
    "    df0 = pd.DataFrame()\n",
    "    for c in cnames:\n",
    "        df0[c] = df[c].fillna(0)\n",
    "\n",
    "    data = df0\n",
    "    # featureDF = []\n",
    "\n",
    "    #create index\n",
    "    indices = data[data.columns[0]]\n",
    "    # create feature subset\n",
    "    # all feature data discluding col [0]: 'id', [-3]: 'q9', [-2]: 'phq', [-1]: 'gad'\n",
    "    featureSubsetS = data[data.columns[1:-3]]\n",
    "\n",
    "    #phq-9/gad-7\n",
    "    if target_type == 'phq':\n",
    "        target = pd.DataFrame(data = data[data.columns[-2]])\n",
    "        target = target.rename(columns={'phq':'target'})\n",
    "        target = target['target'].values.tolist()\n",
    "    elif target_type == 'gad':\n",
    "        target = pd.DataFrame(data = data[data.columns[-1]])\n",
    "        target = target.rename(columns={'gad':'target'})\n",
    "        target = target['target'].values.tolist()\n",
    "    elif target_type == 'q9':\n",
    "        target = pd.DataFrame(data = data[data.columns[-3]])\n",
    "        target = target.rename(columns={'q9':'target'})\n",
    "        target = target['target'].values.tolist()\n",
    "\n",
    "    # split target values into two classes\n",
    "    if target_to_classes == True:\n",
    "        for index, value in enumerate(target):\n",
    "            if value >= split:\n",
    "                target[index] = 1\n",
    "            else: target[index] = 0\n",
    "\n",
    "    # Feature Selection\n",
    "    if feature_selection == \"pca\":\n",
    "        #range of pca features to train and test\n",
    "        nFeatureList = list(np.arange(1,11))\n",
    "    elif feature_selection == 'etc':\n",
    "        #range of etc features to train and test\n",
    "        nFeatureList = list(np.arange(1,11))\n",
    "    elif feature_selection == 'chi2':\n",
    "        # range of chi2 features to train and test\n",
    "        nFeatureList = list(np.arange(1,11))\n",
    "    else: assert False, \"feature selection argument unexpected\"\n",
    "\n",
    "    for index_f, num_f in enumerate(nFeatureList):\n",
    "        #create feature array of this iteration's number of features    \n",
    "        fDF = featureSubsetS\n",
    "        fDF = fDF.to_numpy()    \n",
    "        # cross validation\n",
    "        # leave one out\n",
    "        if cross_validation == \"loo\":\n",
    "            loo = LeaveOneOut()\n",
    "            loo.get_n_splits(fDF)\n",
    "            temp_num=1\n",
    "            for train_index, test_index in loo.split(fDF):\n",
    "                # print(\"train:\", train_index, \"test:\", test_index)\n",
    "                train_data, test_data = fDF[train_index], fDF[test_index]\n",
    "\n",
    "                train_index = train_index.tolist()\n",
    "                test_index = test_index.tolist()\n",
    "                train_data = pd.DataFrame(data = train_data)\n",
    "                test_data = pd.DataFrame(data = test_data)\n",
    "                train_label = pd.DataFrame(data = [target[i] for i in train_index]).reset_index(drop=True)\n",
    "                test_label = pd.DataFrame(data = [target[i] for i in test_index]).reset_index(drop=True)\n",
    "                run_models(train_data, train_label, test_data, test_label, train_index, test_index, num_f, cnames, fnames, random_state, temp_num)\n",
    "                temp_num += 1\n",
    "        # train test split\n",
    "        elif cross_validation == 'tts':\n",
    "            for r in randoms:\n",
    "                random.seed(r)\n",
    "                indices = np.arange(len(target))\n",
    "                train_data, test_data, train_label, test_label, train_index, test_index = train_test_split(fDF, target, indices, test_size=0.3, shuffle = True, random_state = random_state)\n",
    "                \n",
    "                train_index = list(train_index)\n",
    "                test_index = list(test_index)\n",
    "                train_data = pd.DataFrame(data = train_data)\n",
    "                test_data = pd.DataFrame(data = test_data)\n",
    "                train_label = pd.DataFrame(data = train_label)\n",
    "                test_label = pd.DataFrame(data = test_label)\n",
    "\n",
    "                for model in modelTypelist:\n",
    "                    seedlist.append(r)\n",
    "                run_models(train_data, train_label, test_data, test_label, train_index, test_index, num_f, cnames, fnames, r)\n",
    "    \n",
    "\n",
    "    #make results summary df\n",
    "    newDF2 = pd.DataFrame()\n",
    "    newDF2[\"model\"] = mlist\n",
    "    newDF2[\"num_features\"] = flist\n",
    "    newDF2[\"train_index\"] = pqtrain\n",
    "    newDF2[\"test_index\"] = pqtest\n",
    "    newDF2[\"predicted_value\"] = predictions\n",
    "    newDF2[\"real_value\"] = realvalues\n",
    "    newDF2.insert(0, 'modality', modality)\n",
    "    newDF2.insert(1, 'target_type', target_type)\n",
    "    newDF2.insert(2, 'split', split)\n",
    "    newDF2.insert(3, 'feature_selection', feature_selection)\n",
    "    newDF2.insert(4, 'cross_validation', cross_validation)\n",
    "    newDF2.insert(5, 'sampling', sampling)\n",
    "    if cross_validation == 'tts':\n",
    "        newDF2.insert(6, 'random_seed', seedlist)\n",
    "\n",
    "    #make evaluation df\n",
    "    if cross_validation == 'tts':\n",
    "        eval_list = []\n",
    "        for key, val_dict in results.items():\n",
    "            model,f = key[0],key[1]\n",
    "            auc = np.mean(np.array(val_dict[\"auc\"]))\n",
    "            f1 = np.mean(np.array(val_dict[\"f1\"]))\n",
    "            acc = np.mean(np.array(val_dict[\"acc\"]))\n",
    "            eval_list.append(\n",
    "                {\"modality\": modality,\n",
    "                \"target_type\":target_type,\n",
    "                \"split\": split,\n",
    "                \"feature_selection\": feature_selection,\n",
    "                \"cross_validation\": cross_validation,\n",
    "                \"sampling\": sampling,\n",
    "                \"model\": model,\n",
    "                \"num_features\": f,\n",
    "                \"auc\": auc,\n",
    "                \"f1\": f1,\n",
    "                \"accuracy\": acc})\n",
    "        evaluate_df = pd.DataFrame(eval_list)\n",
    "\n",
    "    if cross_validation == 'loo':\n",
    "        eval_list = []\n",
    "        for key, val_dict in results.items():\n",
    "            model,f = key[0],key[1]\n",
    "            auc = roc_auc_score(val_dict[\"true\"], val_dict[\"prediction\"])\n",
    "            f1 = f1_score(val_dict[\"true\"], val_dict[\"prediction\"])\n",
    "            acc = accuracy_score(val_dict[\"true\"], val_dict[\"prediction\"])\n",
    "            # print(val_dict[\"true\"], val_dict[\"prediction\"])\n",
    "            TP, FP, TN, FN = calculate_metrics(val_dict['true'], val_dict['prediction'])\n",
    "            if TP == 0:\n",
    "                precision = 0\n",
    "                sensitivity = 0\n",
    "            else:\n",
    "                precision = TP / (TP + FP)\n",
    "                sensitivity = TP / (TP + FN) # recall\n",
    "            if TN == 0:\n",
    "                specificity = 0\n",
    "            else:\n",
    "                specificity = TN / (TN + FP)\n",
    "            # print(TP, FP, TN, FN)\n",
    "            eval_list.append(\n",
    "                {\"modality\": modality,\n",
    "                \"target_type\": target_type,\n",
    "                \"split\": split,\n",
    "                \"feature_selection\": feature_selection,\n",
    "                \"cross_validation\": cross_validation,\n",
    "                \"sampling\": sampling,\n",
    "                \"model\": model,\n",
    "                \"num_features\": f,\n",
    "                \"auc\": auc,\n",
    "                \"f1\": f1,\n",
    "                \"accuracy\": acc,\n",
    "                \"precision\": precision,\n",
    "                \"sensitivity\": sensitivity,\n",
    "                \"specificity\": specificity,\n",
    "                \"true_positive\": TP,\n",
    "                \"false_positive\": FP,\n",
    "                \"true_negative\": TN,\n",
    "                \"false_negative\": FN})\n",
    "        evaluate_df = pd.DataFrame(eval_list)\n",
    "\n",
    "    #save dfs to csv\n",
    "    newDF2.to_csv(\"resultsAudioTranscript2021/both/\" + modality + \"_\" + target_type + \"_\" + str(split) + \"_\" + feature_selection + \"_\" + cross_validation + \"_\" + sampling + \".csv\", index = False)\n",
    "    evaluate_df.to_csv(\"resultsAudioTranscript2021/both/\" + modality + \"_\" + target_type + \"_\" + str(split) + \"_\" + feature_selection + \"_\" + cross_validation + \"_\" + sampling + \"_evaluate.csv\", index = False)\n",
    "# initialize arguments and constants\n",
    "\n",
    "modelTypelist = [\"NB\", \"LR\", \"SVC1\", \"SVC2\", \"XG\", \"kNN3\", \"RF\"]\n",
    "\n",
    "#parameters\n",
    "mlist = []\n",
    "flist = []\n",
    "#indexes in train and test sets\n",
    "pqtrain = []\n",
    "pqtest = []\n",
    "seedlist = []\n",
    "#results\n",
    "predictions = []\n",
    "realvalues = []\n",
    "results = {}\n",
    "#metrics\n",
    "f1List = []\n",
    "accList = []\n",
    "aucList = []\n",
    "#selected features\n",
    "features_list = []\n",
    "pca_weights = pd.DataFrame()\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
